\documentclass{kuisthesis}			% 特別研究報告書
%\documentclass[master]{kuisthesis}		% 修士論文(和文)
%\documentclass[master,english]{kuisthesis}	% 修士論文(英文)

\usepackage{amsmath} %場合分け
\usepackage{bm}      %太字ベクトル
\usepackage[dvipdfmx]{graphicx} %画像の挿入
\usepackage{comment} %複数行のコメントアウト
\begin{comment}
  このようにして使う
\end{comment}



\def\LATEX{{\rm (L\kern-.36em\raise.3ex\hbox{\sc a})\TeX}}
\def\LATex{\iLATEX\small}
\def\iLATEX#1{L\kern-.36em\raise.3ex\hbox{#1\bf A}\kern-.15em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}
\def\LATEXe{\ifx\LaTeXe\undefined \LaTeX 2e\else\LaTeXe\fi}
\def\LATExe{\ifx\LaTeXe\undefined \iLATEX\scriptsize 2e\else\LaTeXe\fi}
\let\EM\bf
\def\|{\verb|}
\def\<{\(\langle\)}
\def\>{\(\rangle\)}
\def\CS#1{{\tt\string#1}}

\jtitle[時系列クラスタリングを利用した\\未就学児の学習データ分析]%	% 和文題目（内容梗概／目次用）
	{時系列クラスタリングを利用した\\未就学児の学習データ分析}	% 和文題目
        \etitle{Learning Analytics for Preschool Children \\ Using Time Series Clustering}	% 英文題目
\jauthor{内藤　純平}				% 和文著者名
\eauthor{Naito Junpei}			% 英文著者名
\supervisor{鹿島　久嗣 教授}			% 指導教員名
\date{平成29年2月6日}				% 提出年月日
\department{}				% 修士論文の場合の専攻名

\begin{document}
\maketitle					% 「とびら」の出力

\begin{jabstract}				% 和文梗概
%%  コンピュータ技術の発展に伴い、ネットワークに繋がったシステムを利用した授業や受けている授業データの電子化等が行われるようになり、その結果、それらのシステムを利用している学習者の莫大な量の学習データが蓄積されてきている。それらのデータに対して、データ解析の技術を適用し、可視化、解析を行おうとするのがLearning Analyticsである。その目的には、教育方法の有益性の保証や、学習者に対して適切な教材を提供するなどがある。

%%  今回は、未就学の幼児の成長を記録したデータを利用してLearning Analyticsを行う。幼児が受けた検査の結果から得られる特徴を観察し、今後学習を続けるかどうかを予測したり、検査の点数の変化を予測したりすることを試みる。
%  （内容梗概）
  アメリカで、卒業率を向上させるために始まった学習分析が盛んに行われるようになってきている。これは、機械学習・データ解析の技術を教育の分野で行おうという試みである。コンピュータ技術の発展に伴い、教育の分野もコンピュータを利用するようになり、電子的に取り扱うことのできるデータが生まれ、また増えてきたこと、さらには、MOOC等、システムそのものがコンピュータ上にあるような教育が行われるようになり、データの収集、蓄積が自然に行われるようになったことがその背景にある。学習者の学習時間、受けている講義の内容、使っている教材などのデータが蓄積され、そのデータに対して機械学習の技術を使って解析をし、ドロップアウトしそうな問題を抱えた学生を発見し、対処する、学習者に対して最適な教材を勧めるなど、より効率の良い教育、学習ができるようになっている。しかし、学習分析は、対象とする集団によって違う対応をする必要がある場合も多く、特に初等教育・未就学児に対する教育に対しては、学習分析はあまり行われていない。

  本研究では、未就学児への教育に対して学習分析を行い、特に未就学児の学習の継続を予測することを試みる。
利用するデータは、未就学児への評価の性質上、完全に客観的な指標を持ったものではなく、利用者による主観的な評価が幾分か含まれるものである。
ある時期を境として、それ以前までにあるデータを利用し、その後の学習の様子を予測する。
その時期以降にデータが存在することを、学習を継続した基準とする。
予測は2値分類によって行う。

未就学児の評価データを利用し、学習の継続を予測するために、ロジスティック回帰を用いた。その際に、データの時間変化を特徴として与えることができれば、有効であるだろうと考えた。未就学児の評価結果の時間変化を時系列データとして扱い、時系列クラスタリングを行い、その結果を特徴ベクトルとして与え、予測に反映させる。時系列データ間の距離には、DTW距離と、ユークリッド距離の2種類を利用した。児童によって、データが取られた時期や回数が違っているため、それらを合わせて距離の計算をしやすくするために、必要に応じて線形補間を行った。データ間の距離を計算したのちに、クラスタリングを行ったが、その時に利用したのは階層的クラスタリングであり、その中でも、単連結法、完全連結法、群平均法を使った。クラスタ数を10から200まで変化させ、クラスタ数によって精度がどのように変わるのか観察した。精度の評価指標はAUCの値とした。

  未就学児の評価データを学習用のデータと検証用のデータに分け、学習用のデータを利用して、ロジスティック回帰を行い、結果作成された分類器に関して、検証用のデータを利用して精度を見る実験を行ったところ、時系列クラスタリングを使わなかった場合ではAUC値が0.7549、時系列データを利用した場合では、AUCが最大で0.8001となった。時系列クラスタリングに利用する距離や方法を適切に選ぶと、ある時期以前の学習からその時期以降の学習の継続を予測する精度が向上するということを、実験によって示した。
  
\end{jabstract}
\begin{eabstract}				% 英文梗概
  %%Learning Analytics is data anlaytics in educational field. I tried to find useful information by using preschool children studying data.
%  (Description)
  %In the United States, Learning Analytics, which began for improving graduation rate, is increasingly being carried out.
  Learning Analytics was first applied for improving graduation rates in the United States, and it is now increasingly carried out.
Learning Analytics is an attempt to carry out machine learning and data analysis techniques in the field of education. 
%Along with the development of computer technology, the field of education also began to use computers, the data of electronic handling has been born and increased.
As one of the reasons for Learning Analytics's prosperity, along with the development of computer technology, the field of education has come to use computers and therefore, data which can be handled electronically has been generated and has increased.
For other reasons, education such as MOOC where the system itself is on the computer has come to be carried out, and data collection and accumulation has come to be carried out naturally.
Data such as the learning time of the learner, the contents of the lecture, the teaching materials, etc. are accumulated.
By analyzing the data using the machine learning technique, it is possible to discover and deal with students who have problems that are likely to drop out, and to recommend optimum teaching materials for learners.
It can provide more efficient methods for education and learning.
However, Learning Analytics often requires different analysis methods depending on the target group.
For that reason, Learning Analytics has not been often applied to primary education and preschool children.

In this research, we apply Learning Analytics on education for preschool children, especially trying to predict the continuation of learning of preschool children.
The data to be used does not have completely objective indicators, and it includes some subjective evaluation by users due to the nature of evaluation for preschool children.
Based on a certain period of time, we use data before that and predict the status of learning after that.
%Let the fact that data exist after that time as the reference to continue learning.
If data for a child exists after the time threshold, we assume that the child continues learning.
Prediction is done by binary classification.

Logistic regression is used to predict the continuation of learning by using the preschool child's evaluation data.
We consider that it would be effective to use the characteristics of time change of the data as a feature during prediction.
Temporal change in evaluation results of preschool children is handled as time series data, time series clustering is performed on the data, and the result is given as a feature vector and reflected in the prediction.
As the distance between time series data, DTW distance and Euclidean distance are used.
Since the length of the time period and the number of the data are different, in order to make it easy to calculate the distance, linear interpolation is performed.
After calculating the distance between data, we perform clustering. The hierarchical clustering is used at that time.
% among which the single connection method, the complete connection method, and the group average method were used.
We use three hierarchical clustering methods: the single connection method, the complete connection method, and the group average method.
We change the number of clusters from 10 to 200 and observe how the accuracy varies depending on the number of clusters.
We use AUC as the evaluation measure.

The evaluation data of preschool children is divided into data for learning and data for verification, and logistic regression is performed by using learning data.
The accuracy of the created classifier is observed using data for varification.
In the case of not using time series clustering, the AUC value is 0.7549, and when the time series data was used, the AUC is 0.8001 at the maximum.
The results of the experiments show that the accuracy of predicting the continuation of learning is improved if the distance and the method used for time series clustering are appropriately selected.

\end{eabstract}

\tableofcontents				% 目次の出力

\section{はじめに}\label{sec-intro}		% 本文の開始
\subsection{背景}

アメリカにおいて、高等教育機関の卒業率が低いことを受け、卒業率の改善を目的として行った事業があった。伝統的に、そういった卒業できないリスクのある学生の発見は、指導教員からのフィードバックや、GPA、欠席率などの指標からヒューリスティックに求められるルールベースのモデルに基づいて行われていた。ルールベースのアプローチによる手法について、GPAや欠席率などが卒業できるかどうかに関係してくることを明らかにされ、特定の生徒の今後を占う能力があることは認められたものの\cite{book1}、同じモデルを違う学校や違う集団に適用することはできず、一般化することはできなかった\cite{book2}。そこに、ロジスティック回帰、決定木、ランダムフォレストを始めとしたのデータ解析の技術を導入し、ルールベースのアプローチを手作業で行うことに代えたのがLearning Analytics、あるいは、学習分析である。

コンピュータ、インターネットの発展、携帯端末の普及等により、送受信されるデータの量が増え、それに伴い、蓄積されるデータの量が増えた。教育の分野もその例にもれず、扱われるデータの量が増え、学習分析は盛んになっていった。LMS (Learning Manegement Systems、eラーニングの実施に使われる学習教材の配信や成績の管理をするシステム) の導入、MOOC (Massive Open Online Course、インターネット上で、無料で講義を受けることができるサービス) の実施により、学習時間、受けている講義内容、使っている教材などの、特に有用なデータを蓄積していくようになったことも、盛んになった要因である。

学習分析は、学習者と教育機関両方が利益を得られるように行われる。まず、学習者の学習時間、教員とのやりとり、試験の点数などのデータを収集、蓄積する。続いて、他の学習者のデータと合わせ、予測モデル、クラスタリング、パターンマイニング等の技術を用いて学習者の傾向をつかむ。より多くの学習者にとって効果があるようにカリキュラムを修正し、さらに、学習者に適切な学習方法をシステム的に推奨する。最終的に、学習者は効率的な学習を行うことができるようになり、教育機関は効果的な教育が可能になる。また、その過程において、問題を抱えている学生を特定し、その学生に対して、問題が解決するように手助けをすることが可能になる。この、ドロップアウト予測と、その学生への手助けが、最初に示した、高等教育機関における低い卒業率を上げることにもつながり、重要な目的の一つとしてあげることができる\cite{book6}。
%(あとで書く この背景には、LMSやMOOCを始めとしたコンピュータを使った教育システムがある。)

\subsection{課題}
高等教育を対象とした学習分析が盛んに行われていることを述べたが、一方で、幼児教育、初等教育を対象としたものはあまり行われていない。学習時間、試験の点数と言った評点が高等教育のものと同じ意味を持っているとは考えづらく、全く同じ方法でそのまま評価することができないということが考えられる。
また、インターネットやコンピュータを利用した講義などが行われることもなく、単純に得られるデータの種類、量が少ないことも原因として考えられる。
%成績を手作業で入力することはあるだろうが、学習時間などの、コンピュータを使った教育をしているからこそ得られるデータを得ることは難しく、得ていても記録に残すのに割くリソースが無い可能性もある。

特に、未就学児の学習の評価に関しては、子供の能力を計測するのに試験を行う必要があるが、ペーパーテスト等を使って客観的な指標を提供することが難しい。試験を行うのに保護者や教師の補佐が必要になることが考えられ、さらに、試験結果を出す際にも主観的な判断が入る可能性がある。

さらに、高等教育について大きな興味となっているドロップアウト予測に関しても、未就学児の教育に関しては違う解釈をする必要がある。子供が学習を継続するかどうかの判断は、実際に本人が行うものではない。本人が学習に対して興味を示しているかどうかは影響してくるだろうが、子供が興味を示しているか判断することに加え、学習が価値のあるものかどうかを判断する保護者の影響が大きく現れるだろう。

総合的に見て、高等教育と、幼児教育や初等教育とでは、考慮すべき要素が違ってくることに加え、統計処理を目的としてデータを蓄積することも一般的ではなく、実施された回数が少ないこともあり、学習分析の有効性はまだ十分に示されたとは言えない。

\subsection{本研究の概要}
本研究では、未就学児の学習について分析を行い、学習の継続を予測することを検討する。これは、高等教育におけるドロップアウト予測に相当する問題である。
%乳幼児の学習の過程で得られる、保護者や指導者の主観がやや入っている評価データを元に、機械学習の技術を用いて将来学習を継続するかどうかを予測する。
学習を分析するにあたり、ある評価軸について、保護者に依るやや主観の入った評価をデータとし、そのデータを使って機械学習の技術で分析を行い、それに基づいて将来その子供が学習を継続して行うかを予測する。

特に、評価データの中でも、評価点数の時間変化に有用性があると考え、これを予測のための特徴量として利用する。そのためには、時間変化のデータについて時系列クラスタリングを行い、分類されたクラスタを特徴量として予測に加える。

\subsection{結果}
予測には、しちだ・教育研究所から提供されたデータを利用して行った。子供の年齢が0歳から2歳までのデータを利用したが、1999年以降、$1{,}540$人分、$8{,}404$件のデータが記録されていた。2歳以降に学習を継続するかどうかを2値分類で予測し、予測の精度をみたところ、時系列クラスタリングを使わないでAUC値が0.7549、時系列クラスタリングを使った結果、最大でAUC値が0.8001となった。

これにより、未就学児の学習分析には、時系列データのクラスタリング結果が学習の継続を予想するのに有用であることが実験的に示された。

%本研究においては、未就学の幼児のデータを解析する。解析の足がかりとして、幼児の学習を継続するかどうかを予測するという問題を検討する。これは、高等教育におけるドロップアウト予測に相当する。
%乳幼児期の学習の過程で得られる評価データを元に、機械学習の技術を用いて将来学習を継続するかどうかを予測する。
%この問題を、二値分類の問題として解く。その中で、幼児の学習データの時間変化を予測に影響させるため、それらのデータを使って時系列クラスタリングを行い、結果を特徴として線形分類に加える。

\subsection{本論文の構成}
本論文の構成は、次の通りである。第2章にて、関連研究を挙げる。第3章で予測する学習継続と、使用するデータに関して詳細的に述べる。続いて、第4章で予測に際して使用したモデル化の手法について述べる。最後に、第5章で、実験の手順について述べ、その結果を示す。

\section{関連研究}
学習分析における主要な目的の一つは、成績不振者や中退者を事前に予測し、支援に役立てることである。そのため、注意が必要な生徒を予測するための機械学習法が研究されている。

Tamhaneらは、Grade 8 （日本の中学2年生）時点での成績不振者の予測をした。ロジスティック回帰を使い、Grade 1 $\sim$ 7 の長期間の成績情報が、予測に有効であることを示した\cite{book7}。
Aguiarらは、Grade 6 $\sim$ 12 を対象に、中退者とそのタイミングを予測した。その際に、「Grade 6終了時点で中退するか」、「Grade 7 終了時点で中退するか」等の予測問題にすることで、タイミングを予測できるようにした\cite{book8}。
Lakkarajuらは、高校を中退する生徒を予測するためのフレームワークを提案した。このフレームワークを使うと、ランダムフォレストや、ロジスティック回帰などの様々な機械学習法を比較評価することができる。また、重要な特徴を可視化することが可能である。生徒のデータとして、GPAの他に、授業の欠席・遅刻率経済状況などを利用した\cite{book2}。
Vihavainenらは、大学のプログラミング講義の成績不振者を、プログラミング時の行動情報から予測した。コードの修正履歴から、プログラミングにかけた時間、修正前後のコードの編集距離、修正の時間間隔などを取得し、行動情報として利用した\cite{book9}。

これらの研究は、中学生から大学生を対象にしている。幼児教育の成績不振者・非継続者予測における機械学習法の有効性は、十分に示されていない。

\section{問題設定}
\subsection{問題定義}
本研究で取り組む問題は、未就学の子供が行っている学習を、将来継続して行うかを予測することである。予測の材料として使うのは、保護者による、やや主観の入った子供の評価データに加え、子供と保護者に関する情報が含まれるデータである。

データをある時期で区切り、区切り以前の情報を利用し、以降の学習の様子を予測する。 %データの傾向をよく見えるように、また、後に時間的変化を見ることができるように、区切り以前のデータが3以上無いものに関しては、予測には利用しない。
今回は学習継続の予測であるので、区切り以降のデータが存在するか否かを基準にして、子供が学習を継続したか否かを判断する。

データから得られる情報を特徴ベクトルとして捉え、2値分類を行うことで問題を解く。


\subsection{取り扱うデータ}
株式会社「しちだ・教育研究所」より提供されたデータを使う。しちだ・教育研究所では、発達検査というものを行っており、1999年からの検査の結果をデータとして使うことができる。
この発達検査には、「身体的発達」、「知覚的発達」、「言語的発達」、「社会性の発達」の4つの科目があり、それぞれの科目に対し、いくつかのチェック項目が用意されている。例えば、身体的発達のチェック項目には、「棒のぼりの棒に5秒くらいつかまっている」「野球のボールを2〜4メートル投げる」などがある（図\ref{fig:example}）。
\begin{figure}[t]
  \begin{center}
    \includegraphics{./example1.png}
    \caption{チェック項目例}
    \label{fig:example}
  \end{center}
\end{figure}
それらのチェック項目を、子供の保護者が記入し、その回答に基づいて、各項目の点数が決定する方式である。客観的な指標があるチェック項目もあるが、評価者が子供の保護者であるため、その主観が入ってくる可能性がある。
%なお、チェック項目の内容が変わるのは子どもの年齢が２歳になった時と４歳になった時であり、子どもの年齢が一定の範囲である間は質問の内容は変わらず、同じ内容に取り組むこととなる。
%子どもの年齢が０歳から２歳の間、２歳から４歳の間、４歳から６歳の間は、チェック項目の内容は変わらない。なお、配点も変わることはないので、子どものできることが増えるに従って、点数は単調に増加することになる。チェック項目は、平均的に１ヶ月ごとに１点増えることを想定して作成されている。
チェック項目は、平均的に1ヶ月に1点上がることを想定して設定されている。チェック項目は、子供が２歳になった時と４歳になった時に追加されるが、それ以外では内容が変わらず、チェック項目が減ることもない。そのため、点数は単調に増加していく。

点数の他に、子供、あるいはその家庭の情報を示すデータを合わせて得ることができる。
データを分析する上で、重要になりそうな主な特徴を挙げる。

\begin{itemize} % {
\item{会員No} : 教材を受け取っている家庭を一意に定めるために必要な値。
\item{子供No} : 家庭の何番目の子供であるかを示す値。会員Noと子供Noの二つで子供が確定するため、一意に定めるために必要な値でもある。
\item{検査番号} : 子供が発達検査を何回行ったかを表す値。

\item{生年月日} : 子供の生年月日。

\item{検査日} : 発達検査を行った日付。生年月日と合わせて、検査時の、日齢、月齢、年齢などがわかる。

\item{DQ値} : $($身体的発達の点数$+$知覚的発達の点数 $+$ 言語的発達の点数 $+$ 社会性の発達の点数$) \times 100 \div 4 \div $検査時の月齢\\
 で決定される値。

\end{itemize}

チェック項目が2歳になった時に変わることを踏まえ、予測に利用するのは、2歳未満の子供のデータとする。すなわち、2歳以上の時にデータがある場合は学習を継続した、無い場合は学習をやめてしまったと判断する。

ある子供のデータの、月齢と身体的発達の得点を抽出した例を表{\ref{data-exam}}に示す。

\begin{table}[t]
  \caption{データ例}\label{data-exam}
  \begin{center}
    \begin{tabular} {|c|c|c|c|c|c|c|c|c|c|c|c|} \hline
      月齢           & 7 & 9 & 11 & 13 & $\cdots$ & 23 & 25 & 27 & $\cdots$ & 81 & 83 \\ \hline
      身体的発達の得点 & 7 & 8 & 9 &  12 & $\cdots$ & 24 & 26 & 27 & $\cdots$ & 71 & 71\\ \hline
    \end{tabular}
  \end{center}
\end{table}

この子供の場合、2歳以上（月齢が24以上）の時のデータが存在するので、学習を継続したと判断する。

\begin{comment}
  2435	7	7
2873	9	8
3324	11	9
3748	13	12
4152	15	15
4617	17	17
5051	19	19
5500	21	19
5940	23	24
6377	25	26
6775	27	27
7166	29	29
7598	31	31
7989	33	33
8433	35	34
8877	37	35
9394	39	36
9817	41	39
10286	43	41
10694	45	42
11151	47	47
11602	49	48
12010	51	48
12368	53	49
12713	55	50
13033	57	51
13344	59	52
13653	61	52
13926	63	57
14169	65	58
14435	67	61
14660	69	65
14860	71	66
15118	73	67
15363	75	68
15580	77	69
15784	79	70
15975	81	71
16191	83	71
\end{comment}


\begin{comment}
\subsection{問題定義}
発達検査のデータから有益な知識の獲得を目指す。その中で、%しちだの教材を利用している家庭が、今後も継続して利用するかどうかを予測を問題として設定する。
今教材を利用して学習を行っている子ども、ないし家庭が、学習を継続して行うか行わないかを予測することを問題として設定する。

%対象とする家庭は、満二歳未満の子どもの家庭、満二歳以上満四歳未満の子どもの家庭にそれぞれ限定して考える。これは、しちだでの発達検査において、満二歳未満までとそれ以上、満四歳までとそれ以上で内容に変化があるためである。また、それぞれについて、データ数が三つ以上になるものを扱っている。
予測の対象とするのは、2歳未満の子どものデータに限定する。これは、先に述べたように、2歳未満の子どもと、2歳以上の子どもとで発達検査のチェック項目に変化があるためである。また、子ども一人あたりの特徴がよく出るように、2歳未満である間に受けた発達検査の回数が2回以下の子どものデータは、分析するデータに含めないこととする。

子どもが学習を継続したかどうかは、以下のように定義する。
\begin{itemize} % {
\item
  満二歳以上のデータが存在する子ども$\rightarrow$継続して利用した
\item
  満二歳以上のデータが存在しない子ども$\rightarrow$継続して利用しなかった
\end{itemize}
\end{comment}

\section{モデリング手法}
子供が学習を継続するかどうか、という問題を、ロジスティック回帰を使ってモデル化する。その中で、時系列クラスタリングを用い、その特徴量を予測の際に利用した。

\subsection{時系列クラスタリング}
一人の子供に対して継続的に発達検査を行うため、データの時間変化を観察することができる。この時間変化が似ている子供は、学習を継続するか継続しないかに関して、似たような傾向があるだろうという発想に基づき、これら時系列データを使ってクラスタリングを行った結果を予測に反映させる。身体的発達の点数、知覚的発達の点数、言語的発達の点数、社会性の発達の点数の4つに関してクラスタリングを行い、それぞれ子供を10, 20, 50, 100, 200のクラスタに分ける。それぞれのクラスタに分類されているかどうかをバイナリーで表現し、1つのクラスタにつき1つの特徴で表す。

時系列クラスタリングを行うためには、時系列データの距離を計算する必要がある。距離を計算する方法について、DTW距離と、ユークリッド距離の2つを試した。クラスタリングの方法には、階層的クラスタリングを用いた。それぞれについて、簡単に説明する。

\subsubsection{階層的クラスタリング}
階層的クラスタリングは、全てのデータ、クラスタ間の距離（類似度）を計算し、その中で最も距離が小さい（類似度が大きい）２つのデータまたはクラスタを統合し、新たなクラスタとして扱う方法である。最終的には全てのデータを１つのクラスタに統合することができる。仮に10のクラスタに分ける場合、統合されていないデータ、クラスタの数が10になった時点で終了する。

クラスタ間の距離、あるいは、データとクラスタ間の距離を計算する必要がある。これには、単連結法、完全連結法、群平均法の3種類の方法を使った。以下に解説する\cite{book3}。

\begin{itemize} % {
\item{単連結法}\\
  単連結法、もしくは最近隣法は、二つのクラスタ$A, B$について、最も距離の小さいデータ間の距離をクラスタ間の距離とする方法である。クラスタ間の距離を$D\left(A, B\right)$とすると、
  \[
  D(A, B) = \min_{x \in A, y \in B} d(x, y)
  \]
  と表される。ここで、$d \left(x, y \right)$はデータ$x, y$間の距離である。
\item{完全連結法}\\
  完全連結法、もしくは最遠隣法は、二つのクラスタ$A, B$について、最も距離の大きいデータ間の距離をクラスタ間の距離とする方法である。クラスタ間の距離$D \left( A, B \right)$は、次式で表される。
  \[
  D(A, B) = \max_{x \in A, y \in B} d(x, y)
  \]
\item{群平均法}\\
  群平均法は、二つのクラスタ$A, B$について、それぞれの全てのデータ間の距離の平均をクラスタ間の距離とする方法である。クラスタ$A, B$ないのデータの数をそれぞれ$N_A, N_B$とし、クラスタ間の距離$D \left( A, B \right)$は、次式で表される。
  \[
  D(A, B) = \frac{1}{N_A N_B} \sum_{x \in A, y \in B} d(x, y)
  \]
\end{itemize}


\subsubsection{DTW(Dynamic Time Warping)距離}
DTW距離はもともと音などの信号の波形を計算するための方法である。周期や位相だけが違うようなものに関して値が小さくなるようにできている。具体的な定義は以下のようになる。

それぞれ $N$ 個、 $M$ 個のデータを持つ二つの時系列データ$x = (x_1, x_2, \cdots, x_N) \in , y = (y_1, y_2, \cdots, y_M)$がある時、DTW距離$d(x, y)$は、次式で与えられる$D \left( i, j \right)$を使って定義される。

\begin{eqnarray*}
  D(i, j) &=& \min \begin{cases}
    D(i - 1, j - 1) + |x_{i} - y_{j}| \\
    D(i - 1, j) + |x_{i} - y_j| \\
    D(i, j - 1) + |x_i - y_{j}|
  \end{cases} \nonumber \\
  D(i, 0) &=& 0 \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (i = 0, 1, \cdots , N)\nonumber \\
  D(0, j) &=& 0 \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (j = 0, 1, \cdots , M)\nonumber \\
  d(x, y) &=& D(N, M)\\
  (| \cdot | \mbox{は絶対値})
\end{eqnarray*}
  実験の際に、データ数の違う時系列データについて計算した結果を比べる必要があるので、正規化を行うことを考える。その場合、式を次のように修正する。

  \[
  d(x, y) = \frac{1}{N + M} D(N, M)
  \]
  

\subsubsection{ユークリッド距離}
ユークリッド距離は、時系列データを単純にベクトルだと考え、それらのベクトルの差のユークリッドノルムをとったものであり、以下のように定義される。

それぞれ$N$個のデータを持つ二つの時系列データ$x = (x_1, x_2, \cdots , x_N), y = (y_1, y_2, \cdots, y_N)$がある時、ユークリッド距離$d(x, y)$は、

\[
d(x, y) = \sqrt{\sum_i (x_i - y_i)^2}
\]

実験の際に、データ数の違う時系列データについて計算した結果を比べる必要があるので、正規化を行うことを考える。その場合、式を次のようにする。

\[
d(x, y) = \frac{1}{N} \sqrt{\sum_i (x_i - y_i)^2}
\]

ユークリッド距離は、距離を計算する二つの時系列データに関して、データ数が同じでないと計算することができない。データ数の違う時系列データに関しても距離の計算が行えるように、線形補間を行う。

\subsubsection{線形補間}\label{interpolate}
二つのデータ点$(a_1, b_1), (a_2, b_2) \ \  (a_1 \le a_2)$があり、$a_1 \le a \le a_2$となるようなデータ点$(a, b)$が存在しない時、その間線形に変化しているものと仮定してデータを補間するのが線形補間である。具体的には、与えられた$a \in \left[ a_0, a_1 \right] $に関して$(a, b)$を決定する時、以下のようにして行われる。

\[
b = \frac{(a - a_0)b_1 + (a_1 - a)b_0}{a_1 - a_0}
\]

実際に今回子供の学習データ間の距離を計算するのに、線形補間の使い方を2通り試した。

\begin{itemize} % {
\item{A.}生後0ヶ月から24ヶ月までの間、1ヶ月ごとに発達検査を受けたものとし、受けていない月のデータを線形補間で補う。また、生後0ヶ月時点でのデータが存在しない場合は点数を0として扱い、最後に発達検査を受けて以降は、点数は変化していないものとして扱う(図{\ref{fig:example2}})。

  \begin{figure}[t]
  \caption{線形補間Aの例}\label{fig:example2}
  \begin{center}
    \begin{tabular}{c}

      \begin{minipage}{0.5\hsize}
        \begin{center}
          \includegraphics[clip, width=7.0cm]{./A1.png}
          \hspace{1.6cm} A線形補間前
        \end{center}
      \end{minipage}\\

      \begin{minipage}{0.5\hsize}
        \begin{center}
          \includegraphics[clip, width=7.0cm]{./A2.png}
          \hspace{1.6cm} A線形補間後
        \end{center}
      \end{minipage}

    \end{tabular}
  \end{center}
\end{figure}


\item{B.}距離を計算する対象となる2人の子供が、どちらも発達検査を受けている期間に関して、1ヶ月ごとにデータを補間する。1人目の子供が生後3ヶ月から生後12ヶ月まで発達検査を受けており、2人目の子供が生後6ヶ月から生後24ヶ月まで発達検査を受けていたとすると、距離の計算に使うデータは6ヶ月から12ヶ月までのデータとなる(図{\ref{fig:example3}})。
\begin{figure}[t]
  \caption{線形補間Bの例}\label{fig:example3}
  \begin{center}
    \begin{tabular}{c}

      \begin{minipage}{0.5\hsize}
        \begin{center}
          \includegraphics[clip, width=7.0cm]{./B,C1.png}
          \hspace{1.6cm} B線形補間前
        \end{center}
      \end{minipage}\\

      \begin{minipage}{0.50\hsize}
        \begin{center}
          \includegraphics[clip, width=7.0cm]{./B2.png}
          \hspace{1.6cm} B線形補間後
        \end{center}
      \end{minipage}

    \end{tabular}
  \end{center}
\end{figure}


\end{itemize}
全て書いていくと煩雑になるため、実験の項では、A、Bと書くことにする。

\subsection{ロジスティック回帰}
ロジスティック回帰は、ベルヌーイ分布に従う変数の統計的回帰モデルの一種である。
ロジスティック回帰のうち、2値分類のものについて述べる。すなわち、特徴ベクトル${\bm{x}}$に関して、それが属するクラス$\{C_0, C_1\}$を決定する方法について述べる。
\subsubsection{ロジスティックシグモイド関数}
特徴ベクトル${\bm{x}}$が、クラス$C_1$に属する確率$P(C_1|{\bm{x}})$は、
\[
P(C_1 | {\bm{x}}) = \frac{p({\bm{x}} | C_1) P(C_1)} {p({\bm{x}} | C_0) P(C_0) + p({\bm{x}} | C_1) P(C_1)}
\]
で表される。ここで、$P(C_0)$、$P(C_1)$は、それぞれクラスに関する事前確率、$p({\bm{x}} | C_0)$、$p({\bm{x}} | C_1)$は、それぞれクラスの条件付き確率密度関数である。\\

この時、
\[
a = \ln \frac{p({\bm{x}} | C_1) P(C_1)} {p({\bm{x}} | C_0) P(C_0)}
\]
とおくと、
\[
P(C_1 | {\bm{x}}) = \frac{1}{1 + e^{-a}} = \sigma(a)
\]
の式で書くことができる。この$\sigma(a)$をロジスティックシグモイド関数という。

また、
\begin{eqnarray*}
  P(C_0 | {\bm{x}}) &=& \frac{p({\bm{x}} | C_0) P(C_0)} {p({\bm{x}} | C_0) P(C_0) + p({\bm{x}} | C_1) P(C_1)} \nonumber \\
  &=& \frac{1}{1 + e^a} = \sigma(-a) \nonumber \\
  &=& 1 - P(C_1 | {\bm{x}}) \nonumber 
\end{eqnarray*}
である。
\subsubsection{最尤推定}
データ集合$D = \{({\bm{x_n}}, y_n) | n = 1, \cdots, N\}(y \in \{0, 1\}$で、$y = 0$ならそのデータはクラス$C_0$に属する)がある時、クラスの条件付き確率密度関数が、ガウス分布に従い、全てのクラスが同じ共分散行列$\Sigma$を共有すると仮定すると、クラス$C_k(k = 0, 1)$の確率密度関数は、
\[
p({\bm{x | C_k}}) = \frac{1}{(2\pi)^{D / 2}} \frac{1}{|\Sigma|^{1 / 2}} \exp \{-\frac{1}{2}({\bm{x}} - {\bm{\mu_k}})^\top \Sigma^{-1} ({\bm{x}} - {\bm{\mu_k}}) \}
\]
\[
(\Sigma = \frac{1}{N} \sum^N_{n=1} \left( {\bm{x_n}} - {\bm{\mu}})({\bm{x_n}} - {\bm{\mu}} \right)^\top)
\]
で表される。前の式と合わせて、
\[
P(C_1 | {\bm{x}}) = \sigma({\bm{w}}^\top  {\bm{x}} + w_0)
\]
が言える。${\bm{w}}$と$w_0$は次のようになる。
\begin{eqnarray*}
  {\bm{w}} &=& \Sigma^{-1}({\bm{\mu}}_0 - {\bm{\mu}}_1)\\
  w_0 &=& -\frac{1}{2}{\bm{\mu}}^\top_0 \Sigma^{-1} {\bm{\mu}}_0 + \frac{1}{2} {\bm{\mu}}^\top_1 \Sigma^{-1} {\bm{\mu}}_1 + \ln \frac{p(C_0)}{p(C_1)}
\end{eqnarray*}

式を簡単にするために、
\[
  {\bm{w}} = (w_0, {\bm{w}})^\top,\ \
  {\bm{x}} = (1, {\bm{x}})^\top ,\ \
  {\bm{w}}^\top{\bm{x}} + w_0 = {\bm{w}}^\top{\bm{x}}
\]
と表記することにする。

2クラスロジスティック回帰モデルのパラメータの尤度関数は次のようになる。
\[
p({\bm{y}} | {\bm{w}}) = \prod_{n=1}^N P(C_1 | {\bm{x_n}})^{y_n} P(C_0 | {\bm{x_n}})^{1 - y_n}
\]
負の対数をとり、ロジスティックシグモイド関数を使って表すと、
\[
-\sum^N_{n=1}(y_n \ln \sigma({\bm{w}}^\top{\bm{x_n}}) + (1 - y_n) \ln \sigma (-({\bm{w}}^\top{\bm{x_n}}))
\]
この式を、${\bm{w}}$について微分した
\[
\sum^N_{n=1}{\bm{x_n}} ( \sigma({\bm{w}}^\top {\bm{x_n}}) - y_n)
\]
が、0になるような${\bm{w}}$を求める。

データ${\bm{x}}$が得られ、それが属するクラスを推定する時、$p({\bm{x}} | C_0) \ge p({\bm{x}} | C_1)$ならばクラス$C_0$へ、そうで無いならクラス$C_1$へ分類される\cite{book3, book4, book5}。



\section{実験}
\subsection{データセット}
しちだ・教育研究所の発達検査データのうち、2歳未満であり、かつ3回以上発達検査を受けた子供のデータを使った。この条件を満たす子供のデータは$1{,}540$人分、$8{,}404$件あった。これらのデータから、特徴を抽出して、特徴ベクトルとした。使った特徴は以下の通りである。

\begin{itemize} % {
\item 子供No
\item 初回検査日齢 : 一番初めの発達検査が行われた時の子供の日齢
\item 検査時の日齢 : ある子供が受けた全ての発達検査について、発達検査が行われた日の子供の日齢の平均
\item 検査間隔 : ある子供が最初に受けた発達検査から、最後に受けた発達検査までの日数を、発達検査の回数で割ったもの
\item 検査回数 : ある子供が発達検査を受けた回数
\item 身体的発達の点数、知覚的発達の点数、言語的発達の点数、社会性の発達の点数、点数の平均 : それぞれ、ある子供が受けた全ての発達検査についての平均をとった値

\end{itemize}

\subsection{評価指標}
それぞれ出来上がった分類器に対して、AUCを比較する。AUC (Area Under Curve) とは、ROC曲線 (Receiver Operating Characteristics curve) によって作られる図形の面積である。

クラス$C_0$と$C_1$があり、$C_0$に属するデータを正例、$C_1$に属するデータを負例と呼ぶことにする。特徴ベクトル${\bm{x}}$をどちらかのクラスに分類する分類器を$f({\bm{x}}) = p({\bm{x}} | C_0) - p({\bm{x}} | C_1)$で、$f({\bm{x}}) \ge 0$なら、$C_0$、そうで無いなら$C_1$、といったように用意する。この分類器の精度を検定するための、正例が$N_0$個、負例が$N_1$個あるデータセット$\{{\bm{x_n}} | n = 1, 2, \cdots , N_0 + N_1,  f({\bm{x_1}}) \ge f({\bm{x_2}}) \ge \cdots \ge f({\bm{x_{N_0+N_1}}}) \}$について、$a_i$を$\{x_1, x_2, \cdots , x_i \}$中の正例の数、$b_i$を負例の数とする。この時のROC曲線は、点$(a_i / N_0, b_i / N_1)$を繋ぐようにプロットしたものとなる\cite{book3}。

\subsection{比較手法}
時系列データ間の距離を計算するのに、DTW距離とユークリッド距離を使い、それぞれについて正規化を行った場合と、行わなかった場合の両方を用意する。線形補間は、\ref{interpolate}節に示したA、Bの方法を使い、また、線形補間を行わない場合についても考える。線形補間を行わなかった場合は、ユークリッド距離を計算できないデータが多いので、計算しない。階層的クラスタリングの方法に単連結法、完全連結法、群平均法のを使う。クラスタの数は10、20、50、100、200となるようにした。合計で、時系列クラスタリングを150通り行った。時系列クラスタリングを使わないものとも比較し、151の手法を比較する。

\subsection{実験手順}
0歳から2歳までのデータについて、身体的発達の得点を、検査時の月齢と合わせて子供ごとに取り出し、時系列データとして扱う。$1{,}540$の時系列データ間の距離を計算し、距離行列を作成する。距離の計算に際し、線形補間をする場合は適宜行う。作成された距離行列を元に、階層的クラスタリングを行う。その結果を元に、データを10、20、50、100、または200のクラスタに分割し、分類されたクラスタを表すベクトルを子供のデータに追加する。これは、属しているクラスタに対応する要素のみが1、その他の要素は全て0となる10、20、50、100、または200次元のベクトルである。知覚的発達の得点、言語的発達の得点、社会性の発達の得点に関しても同様にする。

子供データから、子供No.、初回検査日齢、検査時の日齢、検査間隔、検査回数、身体的発達、知覚的発達、言語的発達、社会性の発達の得点、それらの平均を取り出し、クラスタリングの結果を加えたベクトルを特徴ベクトルとする。データを、分類器を作成するための学習データと、作成した分類器の精度を検証するための検証データに分ける。学習データと検証データの割合は$80 : 20$とする。学習データに対してロジスティック回帰を行い、それによってできた分類器を使って、検証データに関して予測を行う。予測の精度を、AUCを使って比較する。


\subsection{結果}
クラスタリングを予想に利用しなかった場合の結果を先に述べる。AUC値と、各特徴の重みを表{\ref{table5}}に示す。
\begin{table}[t]
  \begin{center}
    \caption{クラスタリング無しのAUCと特徴の重み}\label{table5}
    \begin{tabular}{|c|c|c|c|} \hline
      \multicolumn{2}{|c|}{AUC値} & \multicolumn{2}{|c|}{0.7549} \\ \hline
      特徴名 & 重み & 特徴名 & 重み \\ \hline \hline
      子供No. & -0.0440 & 初回検査日齢 & -1.0622 \\ \hline
      検査時の日齢 & 2.3269 & 検査間隔 & 0.2380 \\ \hline
      検査回数 & 0.3985 & 得点平均 & 0.1282 \\ \hline
      身体的発達の得点 & 0.0437 & 知覚的発達の得点 & -0.1585 \\ \hline
      言語的発達の得点 & 0.3448 & 社会性の発達の得点 & 0.1993 \\ \hline
    \end{tabular}
  \end{center}
\end{table}
重みを見ると、予測にもっとも影響が大きいのは検査時の日齢であることがわかる。重みが正であるので、検査を受けた時の日齢が高いほど学習を継続しやすいという傾向がわかる。また、2番目に影響が大きいのは初回検査日齢だった。これは重みが負であるので、初めて発達検査を受けた時の日齢が低いほど学習を継続しやすいという傾向がわかる。

クラスタリングを予測に加えた結果について記述していく。まずは、クラスタリングによってできた、あるクラスタのデータを時系列でプロットした図を示す(図{\ref{fig:clust}})。

\begin{figure}[t]
  \begin{center}
    \includegraphics[width = 7.0cm]{./ex-clust.png}
    \caption{クラスタの時系列データ図}\label{fig:clust}
  \end{center}
\end{figure}

時間変化の様子が似ているデータが同じクラスタに分類されていることがわかる。なお、このクラスタは、分類された子供が全て学習を継続しなかった例である。

使ったクラスタリングの方法と、それによってできた分類器のAUC値を、表{\ref{ex1}}、表{\ref{ex2}}、表{\ref{ex3}}、表{\ref{ex4}}、表{\ref{ex5}}に示す。なお、表中のDTWはDTW距離、EUCLはユークリッド距離である。
\begin{table}[tp]
  \begin{center}
    \caption{実験結果}\label{ex1}
%    \thispagestyle{empty}
  \begin{tabular}{ccccc|c} \hline
      距離 & 正規化 & 線形補間 & クラスタリング & クラスタ数 & AUC値 \\ \hline
%    \multicolumn{5}{c|}{クラスタリング無し} & 0.7549 \\ \hline \hline
      DTW & 無し & 無し & 単連結法 & 10 &0.7517 \\
      DTW & 無し & 無し & 単連結法 & 20 &0.7581 \\
      DTW & 無し & 無し & 単連結法 & 50 &0.7549 \\
      DTW & 無し & 無し & 単連結法 & 100 & 0.7581 \\
      DTW & 無し & 無し & 単連結法 & 200 & 0.7547 \\ \hline
      DTW & 無し & 無し & 完全連結法 & 10 & 0.7675 \\
      DTW & 無し & 無し & 完全連結法 & 20 & 0.7779 \\
      DTW & 無し & 無し & 完全連結法 & 50 & 0.7478 \\
      DTW & 無し & 無し & 完全連結法 & 100 & 0.7419 \\
      DTW & 無し & 無し & 完全連結法 & 200 & 0.7382 \\ \hline
      DTW & 無し & 無し & 群平均法 & 10 & 0.7706 \\
      DTW & 無し & 無し & 群平均法 & 20 & 0.7772 \\
      DTW & 無し & 無し & 群平均法 & 50 & 0.7706 \\
      DTW & 無し & 無し & 群平均法 & 100 & 0.7638 \\
      DTW & 無し & 無し & 群平均法 & 200 & 0.7349 \\ \hline \hline
      DTW & 有り & 無し & 単連結法 & 10 & 0.7549 \\
      DTW & 有り & 無し & 単連結法 & 20 & 0.7517 \\
      DTW & 有り & 無し & 単連結法 & 50 & 0.7517 \\
      DTW & 有り & 無し & 単連結法 & 100 & 0.7646 \\
      DTW & 有り & 無し & 単連結法 & 200 & 0.7517 \\ \hline
      DTW & 有り & 無し & 完全連結法 & 10 & 0.7644 \\
      DTW & 有り & 無し & 完全連結法 & 20 & 0.7706 \\
      DTW & 有り & 無し & 完全連結法 & 50 & 0.7507 \\
      DTW & 有り & 無し & 完全連結法 & 100 & 0.7419 \\
      DTW & 有り & 無し & 完全連結法 & 200 & 0.7256 \\ \hline
      DTW & 有り & 無し & 群平均法 & 10 & 0.7740 \\
      DTW & 有り & 無し & 群平均法 & 20 & 0.7770 \\
      DTW & 有り & 無し & 群平均法 & 50 & 0.7449 \\
      DTW & 有り & 無し & 群平均法 & 100 & 0.7349 \\
      DTW & 有り & 無し & 群平均法 & 200 & 0.7223 \\ \hline
  \end{tabular}
  \end{center}
\end{table}


%\thispagestyle{empty}


\begin{table}[tp]
  \caption{実験結果}\label{ex2}
  \begin{center}
  \begin{tabular}{ccccc|c} \hline
      距離 & 正規化 & 線形補間 & クラスタリング & クラスタ数 & AUC値 \\ \hline
      DTW & 無し & A & 単連結法 & 10 & 0.7517 \\
      DTW & 無し & A & 単連結法 & 20 & 0.7517 \\
      DTW & 無し & A & 単連結法 & 50 & 0.7580 \\
      DTW & 無し & A & 単連結法 & 100 & 0.7387 \\
      DTW & 無し & A & 単連結法 & 200 & 0.7483 \\ \hline
      DTW & 無し & A & 完全連結法 & 10 & 0.7710 \\
      DTW & 無し & A & 完全連結法 & 20 & 0.7417 \\
      DTW & 無し & A & 完全連結法 & 50 & 0.7326 \\
      DTW & 無し & A & 完全連結法 & 100 & 0.7261 \\
      DTW & 無し & A & 完全連結法 & 200 & 0.7325 \\ \hline
      DTW & 無し & A & 群平均法 & 10 & 0.7580 \\
      DTW & 無し & A & 群平均法 & 20 & 0.7551 \\
      DTW & 無し & A & 群平均法 & 50 & 0.7544 \\
      DTW & 無し & A & 群平均法 & 100 & 0.7445 \\
      DTW & 無し & A & 群平均法 & 200 & 0.7226 \\ \hline \hline
      DTW & 有り & A & 単連結法 & 10 & 0.7517 \\
      DTW & 有り & A & 単連結法 & 20 & 0.7517 \\
      DTW & 有り & A & 単連結法 & 50 & 0.7580 \\
      DTW & 有り & A & 単連結法 & 100 & 0.7387 \\
      DTW & 有り & A & 単連結法 & 200 & 0.7483 \\ \hline
      DTW & 有り & A & 完全連結法 & 10 & 0.7743 \\
      DTW & 有り & A & 完全連結法 & 20 & 0.7352 \\
      DTW & 有り & A & 完全連結法 & 50 & 0.7292 \\
      DTW & 有り & A & 完全連結法 & 100 & 0.7195 \\
      DTW & 有り & A & 完全連結法 & 200 & 0.7358 \\ \hline
      DTW & 有り & A & 群平均法 & 10 & 0.7580 \\
      DTW & 有り & A & 群平均法 & 20 & 0.7551 \\
      DTW & 有り & A & 群平均法 & 50 & 0.7544 \\
      DTW & 有り & A & 群平均法 & 100 & 0.7445 \\
      DTW & 有り & A & 群平均法 & 200 & 0.7226 \\ \hline
  \end{tabular}
  \end{center}
\end{table}

\begin{table}[tp]
  \begin{center}
  \caption{実験結果}\label{ex3}
  \begin{tabular}{ccccc|c} \hline
      距離 & 正規化 & 線形補間 & クラスタリング & クラスタ数 & AUC値 \\ \hline
      DTW & 無し & B & 単連結法 & 10 & 0.7549 \\
      DTW & 無し & B & 単連結法 & 20 & 0.7549 \\
      DTW & 無し & B & 単連結法 & 50 & 0.7613 \\
      DTW & 無し & B & 単連結法 & 100 & 0.7579 \\
      DTW & 無し & B & 単連結法 & 200 & 0.7646 \\ \hline
      DTW & 無し & B & 完全連結法 & 10 & 0.7613 \\
      DTW & 無し & B & 完全連結法 & 20 & 0.7450 \\
      DTW & 無し & B & 完全連結法 & 50 & 0.7247 \\
      DTW & 無し & B & 完全連結法 & 100 & 0.7121 \\
      DTW & 無し & B & 完全連結法 & 200 & 0.6963 \\ \hline
      DTW & 無し & B & 群平均法 & 10 & 0.7612 \\
      DTW & 無し & B & 群平均法 & 20 & 0.7705 \\
      DTW & 無し & B & 群平均法 & 50 & 0.7347 \\
      DTW & 無し & B & 群平均法 & 100 & 0.7344 \\
      DTW & 無し & B & 群平均法 & 200 & 0.7288 \\ \hline \hline
      DTW & 有り & B & 単連結法 & 10 & 0.7647 \\
      DTW & 有り & B & 単連結法 & 20 & 0.7549 \\
      DTW & 有り & B & 単連結法 & 50 & 0.7451 \\
      DTW & 有り & B & 単連結法 & 100 & 0.7576 \\
      DTW & 有り & B & 単連結法 & 200 & 0.7519 \\ \hline
      DTW & 有り & B & 完全連結法 & 10 & 0.7805 \\
      DTW & 有り & B & 完全連結法 & 20 & 0.7872 \\
      DTW & 有り & B & 完全連結法 & 50 & 0.7605 \\
      DTW & 有り & B & 完全連結法 & 100 & 0.7542 \\
      DTW & 有り & B & 完全連結法 & 200 & 0.7315 \\ \hline
      DTW & 有り & B & 群平均法 & 10 & 0.7744 \\
      DTW & 有り & B & 群平均法 & 20 & 0.7901 \\
      DTW & 有り & B & 群平均法 & 50 & 0.7742 \\
      DTW & 有り & B & 群平均法 & 100 & 0.7387 \\
      DTW & 有り & B & 群平均法 & 200 & 0.7647 \\ \hline
  \end{tabular}
  \end{center}
\end{table}

\begin{table}[tp]
  \begin{center}
  \caption{実験結果}\label{ex4}
  \begin{tabular}{ccccc|c} \hline
      距離 & 正規化 & 線形補間 & クラスタリング & クラスタ数 & AUC値 \\ \hline
      EUCL & 無し & A & 単連結法 & 10 & 0.7549 \\
      EUCL & 無し & A & 単連結法 & 20 & 0.7549 \\
      EUCL & 無し & A & 単連結法 & 50 & 0.7484 \\
      EUCL & 無し & A & 単連結法 & 100 & 0.7516 \\
      EUCL & 無し & A & 単連結法 & 200 & 0.7422 \\ \hline
      EUCL & 無し & A & 完全連結法 & 10 & 0.7739 \\
      EUCL & 無し & A & 完全連結法 & 20 & 0.7482 \\
      EUCL & 無し & A & 完全連結法 & 50 & 0.7219 \\
      EUCL & 無し & A & 完全連結法 & 100 & 0.7423 \\
      EUCL & 無し & A & 完全連結法 & 200 & 0.7483 \\ \hline 
      EUCL & 無し & A & 群平均法 & 10 & 0.7548 \\
      EUCL & 無し & A & 群平均法 & 20 & 0.7417 \\
      EUCL & 無し & A & 群平均法 & 50 & 0.7316 \\
      EUCL & 無し & A & 群平均法 & 100 & 0.7251 \\
      EUCL & 無し & A & 群平均法 & 200 & 0.7483 \\ \hline \hline
      EUCL & 有り & A & 単連結法 & 10 & 0.7549 \\
      EUCL & 有り & A & 単連結法 & 20 & 0.7582 \\
      EUCL & 有り & A & 単連結法 & 50 & 0.7552 \\
      EUCL & 有り & A & 単連結法 & 100 & 0.7742 \\
      EUCL & 有り & A & 単連結法 & 200 & 0.7968 \\ \hline
      EUCL & 有り & A & 完全連結法 & 10 & 0.7517 \\
      EUCL & 有り & A & 完全連結法 & 20 & 0.7517 \\
      EUCL & 有り & A & 完全連結法 & 50 & 0.7484 \\
      EUCL & 有り & A & 完全連結法 & 100 & 0.7612 \\
      EUCL & 有り & A & 完全連結法 & 200 & 0.7768 \\ \hline
      EUCL & 有り & A & 群平均法 & 10 & 0.7517 \\
      EUCL & 有り & A & 群平均法 & 20 & 0.7517 \\
      EUCL & 有り & A & 群平均法 & 50 & 0.7484 \\
      EUCL & 有り & A & 群平均法 & 100 & 0.7612 \\
      EUCL & 有り & A & 群平均法 & 200 & 0.7768 \\ \hline
  \end{tabular}
  \end{center}
\end{table}

\begin{table}[tp]
  \begin{center}
  \caption{実験結果}\label{ex5}
  \begin{tabular}{ccccc|c} \hline
      距離 & 正規化 & 線形補間 & クラスタリング & クラスタ数 & AUC値 \\ \hline
      EUCL & 無し & B & 単連結法 & 10 & 0.7486 \\
      EUCL & 無し & B & 単連結法 & 20 & 0.7551 \\
      EUCL & 無し & B & 単連結法 & 50 & 0.7515 \\
      EUCL & 無し & B & 単連結法 & 100 & 0.7515 \\
      EUCL & 無し & B & 単連結法 & 200 & 0.7581 \\ \hline
      EUCL & 無し & B & 完全連結法 & 10 & 0.7877 \\
      EUCL & 無し & B & 完全連結法 & 20 & 0.7517 \\
      EUCL & 無し & B & 完全連結法 & 50 & 0.7251 \\
      EUCL & 無し & B & 完全連結法 & 100 & 0.7223 \\
      EUCL & 無し & B & 完全連結法 & 200 & 0.6897 \\ \hline
      EUCL & 無し & B & 群平均法 & 10 & 0.7739 \\
      EUCL & 無し & B & 群平均法 & 20 & 0.7349 \\
      EUCL & 無し & B & 群平均法 & 50 & 0.7447 \\
      EUCL & 無し & B & 群平均法 & 100 & 0.7515 \\
      EUCL & 無し & B & 群平均法 & 200 & 0.7190 \\ \hline \hline
      EUCL & 有り & B & 単連結法 & 10 & 0.7614 \\
      EUCL & 有り & B & 単連結法 & 20 & 0.7551 \\
      EUCL & 有り & B & 単連結法 & 50 & 0.7584 \\
      EUCL & 有り & B & 単連結法 & 100 & 0.7775 \\
      EUCL & 有り & B & 単連結法 & 200 & {\bf0.8001} \\ \hline
      EUCL & 有り & B & 完全連結法 & 10 & 0.7605 \\
      EUCL & 有り & B & 完全連結法 & 20 & 0.7502 \\
      EUCL & 有り & B & 完全連結法 & 50 & 0.7208 \\
      EUCL & 有り & B & 完全連結法 & 100 & 0.7467 \\
      EUCL & 有り & B & 完全連結法 & 200 & 0.7658 \\ \hline
      EUCL & 有り & B & 群平均法 & 10 & 0.7869 \\
      EUCL & 有り & B & 群平均法 & 20 & 0.7636 \\
      EUCL & 有り & B & 群平均法 & 50 & 0.7278 \\
      EUCL & 有り & B & 群平均法 & 100 & 0.7338 \\
      EUCL & 有り & B & 群平均法 & 200 & 0.7463 \\ \hline
  \end{tabular}
  \end{center}
\end{table}


%%%%%%%実験結果の項続き


クラスタリングを利用しなかった時のAUC値は0.7549、AUC値が最大となったのは正規化をしたユークリッド距離、線形補間Bを行い、単連結法で200個のクラスタにクラスタリングをした時で、0.8001となり、時系列クラスタリングの利用により、予想の精度にAUCで、最大約0.05の差がついた。

詳しく見る。クラスタ数ごとのAUC値の平均と標準偏差を表{\ref{table1}}に示す。

\begin{table}[t]
  \caption{クラスタ数ごとの評価}\label{table1}
  \begin{center}
    \begin{tabular}{|c|c|c|c|c|c|} \hline
    クラスタ数 & 10 & 20 & 50 & 100 & 200 \\ \hline
    AUC平均値 & 0.7635 & 0.7574 & 0.7463 & 0.7457 & 0.7448 \\ \hline
    AUC標準偏差 & 0.01096 & 0.01384 & 0.1430 & 0.01593 & 0.02505 \\ \hline
    \end{tabular}
    
  \end{center}
\end{table}

クラスタ数が10の時が、AUCの平均値が一番高く、標準偏差が小さい。クラスタ数が増えていくごとにAUCの平均値が小さくなり、標準偏差が大きくなった。クラスタ数が200の時、AUC値は最大0.8001、最小0.6897となり、ばらつきが大きくなる。更にクラスタリングの方法ごとにAUC値の平均を表{\ref{table2}}に示す。
\begin{table}[t]
  \caption{クラスタリング方法ごとの平均値}\label{table2}
  \begin{center}
    \begin{tabular}{|c|c|c|c|c|c|} \hline
      クラスタ数 & 10 & 20 & 50 & 100 & 200 \\ \hline
      単連結法 & 0.7549 & 0.7546 & 0.7543 & 0.7570 & 0.7617 \\ \hline
      完全連結法 & 0.7693 & 0.7559 & 0.7362 & 0.7368 & 0.7341 \\ \hline
      群平均法 & 0.7664 & 0.7617 & 0.7486 & 0.7432 & 0.7386 \\ \hline
    \end{tabular}
  \end{center}
\end{table}
単連結法は、クラスタ数が増えるとAUCが向上する傾向があるが、群平均法と完全連結法では逆に減少の傾向がある。

続いて、距離計算に注目して結果を見る。線形補間の方法ごとのAUCの値を表{\ref{table3}}に示す。
\begin{table}[t]
  \caption{距離と線形補間から見たAUCの平均値}\label{table3}
  \begin{center}
    \begin{tabular}{|c|c|c|} \hline
      距離 & 線形補間 & AUC平均値 \\ \hline
      DTW & 無し & 0.7550 \\ \cline{2-3}
      & A & 0.7455 \\ \cline{2-3}
      & B & 0.7530 \\ \hline
      EUCL & A & 0.7536 \\ \cline{2-3}
      & B & 0.7507 \\ \hline
    \end{tabular}
  \end{center}
\end{table}
DTW距離については、線形補間Aをした場合のAUC値が、線形補間をしない場合、線形補間Bをした場合のAUC値と比べて小さくなっていた。ユークリッド距離については、線形補間の方法によっては大きな差は生じなかった。

最後に、正規化ごとにAUC値を表した結果を表{\ref{table4}}に示す。
\begin{table}[t]
  \caption{距離と正規化の有無から見たAUCの平均値}\label{table4}
  \begin{center}
    \begin{tabular}{|c|c|c|} \hline
      距離 & 正規化 & AUC平均値 \\ \hline
      DTW & 無し & 0.7493 \\ \cline{2-3}
      & 有り & 0.7531 \\ \hline
      EUCL & 無し & 0.7451 \\ \cline{2-3}
      & 有り & 0.7591 \\ \hline
    \end{tabular}
  \end{center}
\end{table}
DTW距離に関しては、正規化の有無による差は大きく現れなかった。ユークリッド距離に関しては、正規化が有る方に、予測精度が高くなる傾向が見られた。


%%%%%%%%実験結果終わり



\begin{comment}

\subsection{1}
線形分類・ロジスティック回帰・変数のスケーリング

使った特徴

・子どもNo・初回検査日齢・検査時の日齢・検査間隔・検査回数・得点平均・身体的発達・知覚的発達・言語的発達・社会的発達


検査時の日齢は、検査日と誕生日の間の日数から計算する。

初回検査日齢は、一回目の検査の時の日齢

検査間隔は、二歳未満での最初の検査の日と最後の検査の日の間の日数を検査回数で割ったもの

得点平均は身体的発達、知覚的発達、言語的発達、社会的発達の各得点の平均

得点平均、身体的発達、知覚的発達、言語的発達、社会的発達の得点は、子どもごとの二歳未満で受けた全ての発達検査の平均

誤答率 0.237012987013

正$\rightarrow$負 0.07179

負$\rightarrow$正 0.165584

AUC 0.764731935715

\begin{table}[htb]
  \caption{線形分類の際の各特徴変数の重み}
  \begin{tabular}{|c|c|} \hline
    特徴名 & 重み\\ \hline
    子どもNo & -0.05307687\\
    初回検査日齢 & -1.65984605\\
    検査時の日齢 & 2.93825341\\
    検査間隔 & 0.10202452\\
    検査回数 & 0.19636222\\
    得点平均 & 0.02756164\\
    身体的発達の得点 & -0.19509496\\
    知覚的発達の得点 & -0.2123578\\
    言語的発達の得点 & 0.20917941\\
    社会性の発達の得点 & 0.15129033\\ \hline
  \end{tabular}
\end{table}

\subsection{2}
線形分類・ロジスティック回帰・変数のスケーリング・DTW距離を使ったクラスタリング

身体的発達、知覚的発達、言語的発達、社会的発達の各得点の時間変化を使い、それぞれについてクラスタリングを行う。DTWを使って距離を計算し、最遠隣法でクラスタリングをする。

使った特徴

・子どもNo・初回検査日齢・検査児の日齢・検査間隔・検査回数・身体的発達の得点・知覚的発達の得点・言語的発達の得点・社会性の発達の得点・得点平均・身体的発達の得点の時間変化を使ったクラスタリングの結果・知覚的発達の得点の時間変化を使ったクラスタリングの結果・言語的発達の得点の時間変化を使ったクラスタリングの結果・社会性の発達の時間変化を使ったクラスタリングの結果

誤答率 0.224025974026

AUC値 0.777344244316

\begin{table}[hbt]
  \begin{tabular}{|c|c|} \hline
    特徴名 & 重み \\ \hline
    子どもNo & -0.04797697\\
    初回検査日齢 & -1.78500352\\
    検査時の日齢 & 3.112356\\
    検査間隔 & 0.17631743\\
    検査回数 & 0.08605869\\
    得点平均 & -0.02231287\\
    身体的発達の得点 & -0.24809413\\
    知覚的発達の得点 & -0.24975621\\
    言語的発達の得点 & 0.0587641\\
    社会性の発達の得点 & 0.39267555\\ \hline
  \end{tabular}
\end{table}

クラスタリングの結果を特徴にしたものの重みは絶対値が小さめ
\subsection{3}
線形補間を行った上でのクラスタリング

１ヶ月ごとに発達検査を行ったものと仮定し、記録がない部分は線形補間によって補う

線形補間は、生後０ヶ月時点での各得点を0とし、最後に発達検査を受けて以降は点数が変わらないものと仮定して行う。

DTW距離を計算し、最遠隣法でクラスタリングを行う。

誤答率 0.233766233766

AUC値 0.768169738896

\begin{table}[hbt]
  \begin{tabular}{|c|c|} \hline
    特徴名 & 重み \\ \hline
    子どもNo & -0.0566515233\\
    初回検査日齢 & -1.33899318\\
    検査時の日齢 & 2.93693996\\
    検査間隔 & 0.120863148\\
    検査回数 & 0.159222268\\
    得点平均 & -0.121865551\\
    身体的発達の得点 & -0.784592781\\
    知覚的発達の得点 & -0.1652227570\\
    言語的発達の得点 & 0.0929367725\\
    社会性の発達の得点 & 0.491234707\\ \hline
  \end{tabular}
\end{table}

\subsection{4}
3と同じ線形補間を行ったあと、ユークリッド距離を計算する

誤答率 0.233766233766

AUC値 0.768169738896

\begin{table}[hbt]
  \begin{tabular}{|c|c|} \hline
    特徴名 & 重み \\ \hline
    子どもNo & -0.0578365392 \\
    初回検査日齢 & -1.45109392\\
    検査時の日齢 & 2.84756127 \\
    検査間隔 & 0.109499811 \\
    検査回数 & 0.156314510 \\
    得点平均 & -0.0370518841 \\
    身体的発達の得点 & -0.217099983 \\
    知覚的発達の得点 & -0.296430074 \\
    言語的発達の得点 & -0.342508677 \\
    社会性の発達の得点 & 0.0554938962 \\ \hline
  \end{tabular}
\end{table}

\subsection{5}
3、4と同様に線形補間を行うが、距離の計算には、それぞれの子どもが発達検査を受けている間のデータのみを使う。発達検査を受けている期間が重ならない場合は、距離を非常に大きい値に設定する。

DTW距離を計算し、最遠隣法でクラスタリングする。

誤答率 0.224025974026

AUC値 0.777344244316

\begin{table}[hbt]
  \begin{tabular}{|c|c|}\hline
    特徴名 & 重み \\ \hline
    子どもNo & -0.04364524 \\
    初回検査日齢 & -1.74397305 \\
    検査間隔 & 2.98377916 \\
    検査回数 & 0.06854792 \\
    得点平均 & -0.02159432 \\
    身体的発達の得点 & -0.30145541 \\
    知覚的発達の得点 & -0.0851175 \\
    言語的発達の得点 & 0.19093143 \\
    社会性の発達の得点 & 0.33463852 \\ \hline
  \end{tabular}
\end{table}

\subsection{6}
それぞれの子どもが発達検査を受けている期間のうち、どちらかの結果が存在する月に関して線形補間を行い、DTW距離を計算する。発達検査を受けている期間が重ならない場合は、距離を非常に大きい値にする。

%%それぞれの子どもが発達検査を受けている期間のうち、どちらかの結果が存在する月のみに関して線形補間を行い、DTW距離を計算する。発達検査を受けている期間が重ならない場合は、距離を非常に大きい値にする。
誤答率 0.230519480519

AUC値 0.771354452271

\begin{table}[hbt]
  \begin{tabular}{|c|c|}\hline
    特徴名 & 重み \\ \hline
    子どもNo & -0.0307041971 \\
    初回検査日齢 & -1.70566765 \\
    検査時の日齢 & 3.04863302 \\
    検査間隔 & 0.109264780 \\
    検査回数 & 0.237987944 \\
    得点平均 & 0.0203148896 \\
    身体的発達の得点 & -0.240283184 \\
    知覚的発達の得点 & -0.0361334613 \\
    言語的発達の得点 & 0.187786375 \\
    社会性の発達の得点 & 0.21129960 \\ \hline
  \end{tabular}
\end{table}

\subsection{7}
6と同じ線形補間を行い、ユークリッド距離を計算する。

誤答率 0.230519480519

AUC値 0.770595182857

\begin{table}[hbt]
  \begin{tabular}{|c|c|} \hline
    特徴名 & 重み \\ \hline
    子どもNo & -0.0360799866 \\
    初回検査日齢 & -1.61595981 \\
    検査時の日齢 & 2.90693110 \\
    検査間隔 & 0.1050144304 \\
    検査回数 & 0.222632325 \\
    得点平均 & 0.0313556105 \\
    身体的発達の得点 & -0.253600431 \\
    知覚的発達の得点 & 0.00156955002 \\
    言語的発達の得点 & 0.278408538 \\
    社会性の発達の得点 & 0.142081923\\ \hline
  \end{tabular}
\end{table}

\subsection{8}
5と同じ線形補間を行い、ユークリッド距離を計算する

誤答率 0.253246753247

AUC値 0.74792255452

\begin{table}[hbt]
  \begin{tabular}{|c|c|} \hline 
    特徴名 & 重み \\ \hline
    子どもNo & -0.07042258 \\
    初回検査日齢 & -1.63019113 \\
    検査時の日齢 & 2.94523183 \\
    検査間隔 & 0.12233782 \\
    検査回数 & 0.22602245 \\
    得点平均 & 0.03298176 \\
    身体的発達 & -0.20123974 \\
    知覚的発達 & -0.02643571 \\
    言語的発達 & 0.18001634 \\
    社会性の発達の得点 & 0.21561254 \\ \hline
  \end{tabular}
\end{table}

\end{comment}

\section{終わりに}
本研究では、未就学児に対して学習分析を行うことを試み、特に学習の継続を予想することを行った。子供の保護者による、やや主観の入った評価データを用い、ロジスティック回帰を使った2値分類の結果、AUC値は$0.7 \sim 0.8$ほどを示す結果となった。この評価データは、高いとは言えずとも、まずまずの予測性能を持っていると言えるだろう。さらに、時系列クラスタリングを予測に利用したところ、利用しなかった場合と比べ、AUCに最大で0.05の差が出たことから、評価点の時間変化には、予測能力があることが実験的に示された。

\acknowledgments
本研究を進めるにあたり丁寧かつ熱心なご指導、御助言を賜りました鹿島久嗣教授に厚くお礼申し上げます。また、実験や論文執筆に際して細やかな配慮とともにお力添えくださった馬場雪乃助教に心より感謝申し上げます。本研究に当たりまして、数々のご支援を賜った、しまねソフト研究開発センターの布野卓也氏、高木丈智氏、データをご提供頂いた、株式会社しちだ・教育研究所様に深く感謝いたします。そして、普段から議論を通じて多くの知識や示唆を頂いた鹿島研究室の皆さまに心より感謝いたします。
%{謝辞}\label{Appsub-Acknowlegments}

\nocite{*}
\bibliographystyle{kuisunsrt}
\bibliography{sotsuron}

%\section{参考文献}\label{appsub-references}

\end{document}
